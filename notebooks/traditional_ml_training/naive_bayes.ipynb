{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588f2771",
   "metadata": {},
   "source": [
    "# Multi-Label Email Classification Project\n",
    "\n",
    "This notebook implements a multi-label text classification system for emails using various machine learning models. Multi-label classification allows each email to be assigned multiple categories simultaneously (e.g., an email could be both \"Business\" and \"Customer Support\").\n",
    "\n",
    "## Project Overview\n",
    "- **Dataset**: Multi-class email classification dataset\n",
    "- **Task**: Predict multiple labels for each email\n",
    "- **Models**: ComplementNB, MultinomialNB, LogisticRegression\n",
    "- **Features**: TF-IDF vectors with bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddb7f5",
   "metadata": {},
   "source": [
    "## Import Libraries and Setup\n",
    "\n",
    "We import all necessary libraries for:\n",
    "- **Text processing**: `re` for regex, `nltk` for NLP operations\n",
    "- **Data handling**: `datasets` for loading data, `sklearn` for ML tasks\n",
    "- **Models**: Naive Bayes variants, Logistic Regression, Random Forest\n",
    "- **Evaluation**: Metrics to measure model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92226eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hout\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Regular expressions for text cleaning\n",
    "import re\n",
    "\n",
    "# Dataset loading\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Train-test splitting and preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Feature extraction (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Multi-label classification wrapper\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Classification models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# NLP tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download stopwords (common words like \"the\", \"is\", \"and\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Initialize text processing tools\n",
    "stop_words = set(stopwords.words(\"english\"))  # Words to remove\n",
    "stemmer = PorterStemmer()  # Reduces words to their root form (e.g., \"running\" -> \"run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4c08a",
   "metadata": {},
   "source": [
    "## Define Text Preprocessing Function\n",
    "\n",
    "This function cleans and normalizes email text to improve model performance:\n",
    "1. **Remove placeholders** like [Your Name]\n",
    "2. **Lowercase** all text for consistency\n",
    "3. **Remove punctuation** to focus on words\n",
    "4. **Remove stopwords** (common words that don't add meaning)\n",
    "5. **Stem words** to reduce them to root forms\n",
    "6. **Collapse whitespace** for clean output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a536f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_email(text):\n",
    "    \"\"\"\n",
    "    Preprocess email text for machine learning.\n",
    "    \n",
    "    This function applies multiple text cleaning steps to normalize\n",
    "    the input and make it suitable for feature extraction.\n",
    "    \n",
    "    Steps:\n",
    "    - Remove placeholders like [Your Name]\n",
    "    - Lowercase conversion\n",
    "    - Remove punctuation\n",
    "    - Remove stopwords (common words)\n",
    "    - Apply stemming (reduce words to root form)\n",
    "    - Collapse extra whitespace\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw email text\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned and normalized text\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove square bracket placeholders (e.g., [Company Name])\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Convert to lowercase for consistency\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation, keep only alphanumeric and spaces\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenize (split into words)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    # Keep only words longer than 1 character and not in stopwords list\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t not in stop_words and len(t) > 1]\n",
    "    \n",
    "    # Step 6: Rejoin tokens into a single string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c66d9",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset\n",
    "\n",
    "We load the multi-class email classification dataset from Hugging Face and combine the subject and body of each email into a single text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ab9b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample raw text: Meeting Reminder: Quarterly Sales Review Tomorrow Dear Team, Just a friendly reminder that our Quarterly Sales Review meeting is scheduled for tomorrow at 10:00 AM in the conference room. Please make sure to bring your sales reports and any relevant updates. Coffee and pastries will be provided. Looking forward to a productive meeting. Best regards, [Your Name]\n",
      "Sample raw labels: ['Business', 'Reminders']\n",
      "Total examples: 2105\n"
     ]
    }
   ],
   "source": [
    "# Load the multi-class email classification dataset\n",
    "dataset = load_dataset(\"imnim/multiclass-email-classification\")\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Combine subject and body into single text field\n",
    "# Handle None values by converting to empty string\n",
    "texts_raw = [(s or \"\") + \" \" + (b or \"\") for s, b in zip(train_data[\"subject\"], train_data[\"body\"])]\n",
    "\n",
    "# Extract labels (each email can have multiple labels)\n",
    "labels_raw = train_data[\"labels\"]\n",
    "\n",
    "# Display sample data to understand structure\n",
    "print(\"Sample raw text:\", texts_raw[0])\n",
    "print(\"Sample raw labels:\", labels_raw[0])\n",
    "print(\"Total examples:\", len(texts_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdde94",
   "metadata": {},
   "source": [
    "## Split Data and Preprocess\n",
    "\n",
    "We split the data into training (80%) and testing (20%) sets, then apply our preprocessing function to clean the text. Labels are converted to binary format using MultiLabelBinarizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cccc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed example (train index 0):\n",
      "RAW: Important Update: Company Meeting Schedule Change Dear Team, Due to unforeseen circumstances, the upcoming company meeting scheduled for Friday has been rescheduled to Monday next week at 10:00 AM. We apologize for any inconvenience this may cause and appreciate your understanding. Please make the necessary adjustments to your calendars. Thank you. Best regards, [Your Name]\n",
      "CLEAN: import updat compani meet schedul chang dear team due unforeseen circumst upcom compani meet schedul friday reschedul monday next week 10 00 apolog inconveni may caus appreci understand pleas make necessari adjust calendar thank best regard\n"
     ]
    }
   ],
   "source": [
    "# Split data into 80% training and 20% testing\n",
    "# Use random_state for reproducibility\n",
    "X_train_raw, X_test_raw, labels_train_raw, labels_test_raw = train_test_split(\n",
    "    texts_raw, labels_raw, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Apply preprocessing to both train and test sets\n",
    "# This is done AFTER splitting to prevent data leakage\n",
    "X_train = [preprocess_email(t) for t in X_train_raw]\n",
    "X_test = [preprocess_email(t) for t in X_test_raw]\n",
    "\n",
    "# Convert labels to binary format for multi-label classification\n",
    "# MultiLabelBinarizer creates a binary matrix where 1 = label present, 0 = label absent\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(labels_train_raw)  \n",
    "y_test = mlb.transform(labels_test_raw)        \n",
    "\n",
    "# Show example of preprocessing effect\n",
    "print(\"Processed example (train index 0):\")\n",
    "print(\"RAW:\", X_train_raw[0][:400])\n",
    "print(\"CLEAN:\", X_train[0][:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca0c32",
   "metadata": {},
   "source": [
    "## Feature Extraction with TF-IDF\n",
    "\n",
    "Convert text to numerical features using TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "- **max_features=15000**: Use top 15,000 most important terms\n",
    "- **ngram_range=(1,2)**: Consider both single words and word pairs\n",
    "- **sublinear_tf=True**: Apply logarithmic scaling to term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb0c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature count: 12641\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "# TF-IDF converts text to numerical features by weighing term importance\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000,      \n",
    "    ngram_range=(1, 2),    \n",
    "    sublinear_tf=True      \n",
    ")\n",
    "\n",
    "# Fit vectorizer on training data and transform both sets\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  \n",
    "X_test_vec = vectorizer.transform(X_test)       \n",
    "\n",
    "print(\"TF-IDF feature count:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a1ec2",
   "metadata": {},
   "source": [
    "## Define Models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee800c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of models for potential batch training\n",
    "# OneVsRestClassifier wraps each model to handle multi-label classification\n",
    "models = {\n",
    "    \"ComplementNB\": OneVsRestClassifier(ComplementNB()),\n",
    "    \"LogisticRegression\": OneVsRestClassifier(LogisticRegression(max_iter=1000)),\n",
    "    \"RandomForest\": OneVsRestClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e6c23",
   "metadata": {},
   "source": [
    "## Train and Evaluate ComplementNB\n",
    "\n",
    "**Complement Naive Bayes** is designed to handle imbalanced datasets by learning from the complement of each class. It often performs better than standard Naive Bayes for text classification.\n",
    "\n",
    "**ComplementNB Model Performance Summary**\n",
    "\n",
    "- The Complement Naive Bayes model achieved 62% subset accuracy, with Micro F1 = 0.796 and Macro F1 = 0.759, showing strong performance overall.\n",
    "\n",
    "- It performed very well on categories with clear keyword patterns such as Finance & Bills, Travel & Bookings, Business, and Events & Invitations (F1-scores above 0.80).\n",
    "\n",
    "- Moderate performance was seen in Customer Support, Promotions, and Reminders.\n",
    "\n",
    "- The model struggled with categories that have more personal or vague language, especially Personal and Newsletters, due to high variability in writing style.\n",
    "\n",
    "Overall, ComplementNB shows good generalization but still has difficulty with classes that have less consistent or more informal text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e534302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ComplementNB\n",
      "Subset Accuracy: 0.620, Micro F1: 0.796, Macro F1: 0.759\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Business       0.76      0.93      0.83       174\n",
      "    Customer Support       0.80      0.73      0.76        48\n",
      "Events & Invitations       0.76      0.91      0.82       127\n",
      "     Finance & Bills       0.87      0.98      0.93        63\n",
      "     Job Application       1.00      0.81      0.89        26\n",
      "         Newsletters       0.88      0.46      0.60        46\n",
      "            Personal       1.00      0.21      0.35        52\n",
      "          Promotions       0.72      0.78      0.75        27\n",
      "           Reminders       0.68      0.67      0.68        70\n",
      "   Travel & Bookings       1.00      0.95      0.97        58\n",
      "\n",
      "           micro avg       0.80      0.79      0.80       691\n",
      "           macro avg       0.85      0.74      0.76       691\n",
      "        weighted avg       0.82      0.79      0.78       691\n",
      "         samples avg       0.82      0.82      0.80       691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hout\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Initialize ComplementNB model wrapped in OneVsRestClassifier\n",
    "# OneVsRestClassifier trains one binary classifier per label\n",
    "clf_cnb = OneVsRestClassifier(ComplementNB())\n",
    "clf_cnb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict probabilities for each label\n",
    "y_proba_cnb = clf_cnb.predict_proba(X_test_vec)\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred_cnb = (y_proba_cnb >= 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred_cnb)       # Subset accuracy (all labels must match)\n",
    "micro = f1_score(y_test, y_pred_cnb, average='micro')  # Micro-averaged F1\n",
    "macro = f1_score(y_test, y_pred_cnb, average='macro')  # Macro-averaged F1\n",
    "\n",
    "print(\"✅ ComplementNB\")\n",
    "print(f\"Subset Accuracy: {acc:.3f}, Micro F1: {micro:.3f}, Macro F1: {macro:.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cnb, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787577e",
   "metadata": {},
   "source": [
    "## Train and Evaluate MultinomialNB\n",
    "\n",
    "**Multinomial Naive Bayes** is a fast text-classification model that learns from word frequency patterns. It works best when each class has clear, consistent vocabulary, but struggles with categories that use varied or informal language.\n",
    "\n",
    "**MultinomialNB Model Performance Summary** \n",
    "\n",
    "- The model achieved 58.9% subset accuracy, with Micro F1 = 0.776 and Macro F1 = 0.701.\n",
    "\n",
    "- It performed very well on categories like Finance & Bills, Travel & Bookings, Business, Events & Invitations, and Job Applications, where text patterns are more consistent.\n",
    "\n",
    "- Performance was moderate for Promotions and Reminders.\n",
    "\n",
    "- The model struggled significantly with Customer Support, Newsletters, and Personal emails due to highly varied and less predictable language.\n",
    "\n",
    "To sum up, MultinomialNB is effective for structured and keyword-rich categories, but less reliable for categories with informal or diverse writing styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328ec88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MultinomialNB\n",
      "Subset Accuracy: 0.589, Micro F1: 0.776, Macro F1: 0.701\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Business       0.76      0.93      0.83       174\n",
      "    Customer Support       1.00      0.33      0.50        48\n",
      "Events & Invitations       0.86      0.87      0.86       127\n",
      "     Finance & Bills       0.97      0.92      0.94        63\n",
      "     Job Application       1.00      0.81      0.89        26\n",
      "         Newsletters       0.93      0.30      0.46        46\n",
      "            Personal       1.00      0.12      0.21        52\n",
      "          Promotions       0.86      0.67      0.75        27\n",
      "           Reminders       0.80      0.47      0.59        70\n",
      "   Travel & Bookings       1.00      0.93      0.96        58\n",
      "\n",
      "           micro avg       0.86      0.71      0.78       691\n",
      "           macro avg       0.92      0.63      0.70       691\n",
      "        weighted avg       0.88      0.71      0.74       691\n",
      "         samples avg       0.81      0.74      0.76       691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hout\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train MultinomialNB model\n",
    "clf_mnb = OneVsRestClassifier(MultinomialNB())\n",
    "clf_mnb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict probabilities and convert to binary predictions\n",
    "y_proba_mnb = clf_mnb.predict_proba(X_test_vec)\n",
    "y_pred_mnb = (y_proba_mnb >= 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred_mnb)\n",
    "micro = f1_score(y_test, y_pred_mnb, average='micro')\n",
    "macro = f1_score(y_test, y_pred_mnb, average='macro')\n",
    "\n",
    "print(\"✅ MultinomialNB\")\n",
    "print(f\"Subset Accuracy: {acc:.3f}, Micro F1: {micro:.3f}, Macro F1: {macro:.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mnb, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e8ea3",
   "metadata": {},
   "source": [
    "## Train and Evaluate Logistic Regression\n",
    "\n",
    "**Logistic Regression** is a linear model that often performs well for text classification. It can capture more complex relationships than Naive Bayes models.\n",
    "\n",
    "**Logistic Regression Model Summary**\n",
    "\n",
    "- The Logistic Regression model achieved 61.3% subset accuracy, with Micro F1 = 0.795 and Macro F1 = 0.731, showing strong overall performance.\n",
    "\n",
    "- It performed very well on consistent categories like Business, Events & Invitations, Finance & Bills, and Travel & Bookings (high F1-scores).\n",
    "\n",
    "- Performance was moderate on Customer Support, Promotions, and Reminders.\n",
    "\n",
    "- It struggled with Newsletters and Personal, where writing style varies a lot, leading to low recall.\n",
    "\n",
    "In Summary, Logistic Regression generalizes well across most classes but still finds informal or highly varied text difficult to classify accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c736e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LogisticRegression\n",
      "Subset Accuracy: 0.613, Micro F1: 0.795, Macro F1: 0.731\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            Business       0.78      0.95      0.85       174\n",
      "    Customer Support       0.91      0.62      0.74        48\n",
      "Events & Invitations       0.81      0.90      0.85       127\n",
      "     Finance & Bills       0.97      0.94      0.95        63\n",
      "     Job Application       1.00      0.73      0.84        26\n",
      "         Newsletters       0.93      0.28      0.43        46\n",
      "            Personal       1.00      0.21      0.35        52\n",
      "          Promotions       0.94      0.59      0.73        27\n",
      "           Reminders       0.80      0.47      0.59        70\n",
      "   Travel & Bookings       1.00      0.93      0.96        58\n",
      "\n",
      "           micro avg       0.85      0.74      0.80       691\n",
      "           macro avg       0.91      0.66      0.73       691\n",
      "        weighted avg       0.87      0.74      0.77       691\n",
      "         samples avg       0.81      0.77      0.78       691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hout\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Logistic Regression model\n",
    "# max_iter=1000 allows more iterations for convergence\n",
    "clf_lr = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "clf_lr.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict probabilities and convert to binary predictions\n",
    "y_proba_lr = clf_lr.predict_proba(X_test_vec)\n",
    "y_pred_lr = (y_proba_lr >= 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred_lr)\n",
    "micro = f1_score(y_test, y_pred_lr, average='micro')\n",
    "macro = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "print(\"✅ LogisticRegression\")\n",
    "print(f\"Subset Accuracy: {acc:.3f}, Micro F1: {micro:.3f}, Macro F1: {macro:.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30535027",
   "metadata": {},
   "source": [
    "## Model Comparison: MultinomialNB vs ComplementNB vs Logistic Regression\n",
    "\n",
    "**MultinomialNB:** Fast, works well on classes with consistent vocabulary, but struggles with informal or varied text (Customer Support, Newsletters, Personal).\n",
    "\n",
    "**ComplementNB:** Handles imbalanced classes better, improves recall, still weaker on highly variable text.\n",
    "\n",
    "**Logistic Regression:** Most balanced across categories, good precision and recall, handles diverse text better than NB models.\n",
    "\n",
    "Summary: ComplementNB has slightly higher overall scores and handles class imbalance best, Logistic Regression is most stable across categories, and MultinomialNB is a fast baseline for structured text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc3225",
   "metadata": {},
   "source": [
    "## Analyze Specific Examples\n",
    "\n",
    "Let's examine how each model performs on specific test examples. We'll see:\n",
    "- The original email text\n",
    "- The cleaned/processed version\n",
    "- True labels vs. predicted labels\n",
    "- Prediction probabilities for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55f80c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Example #15 (ComplementNB)\n",
      "Raw text: Important Update: Company Policy Changes Dear Team, I hope this email finds you well. I wanted to inform you about some recent updates to our company policies. These changes are aimed at improving efficiency and ensuring compliance with industry standards. Please review the attached document for detailed information. Should you have any questions or need further clarification, feel free to reach o ...\n",
      "Cleaned text: import updat compani polici chang dear team hope email find well want inform recent updat compani polici chang aim improv effici ensur complianc industri standard pleas review attach document detail inform question need clarif feel free reach thank attent matter best regard ...\n",
      "True labels: ['Business', 'Customer Support']\n",
      "Predicted labels: ['Business', 'Customer Support']\n",
      "Probabilities: {'Business': 0.982, 'Customer Support': 0.908, 'Events & Invitations': 0.004, 'Finance & Bills': 0.029, 'Job Application': 0.001, 'Newsletters': 0.0, 'Personal': 0.002, 'Promotions': 0.0, 'Reminders': 0.003, 'Travel & Bookings': 0.003}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #72 (ComplementNB)\n",
      "Raw text: Important Updates Regarding Your Account Dear Customer, We are writing to inform you about some important updates related to your account. Please log in to your account to review the changes and ensure that your information is up to date. If you have any questions or need assistance, feel free to contact our customer support team. Thank you for your attention to this matter. Sincerely, [Company Na ...\n",
      "Cleaned text: import updat regard account dear custom write inform import updat relat account pleas log account review chang ensur inform date question need assist feel free contact custom support team thank attent matter sincer ...\n",
      "True labels: ['Customer Support', 'Finance & Bills']\n",
      "Predicted labels: ['Customer Support', 'Finance & Bills']\n",
      "Probabilities: {'Business': 0.042, 'Customer Support': 0.66, 'Events & Invitations': 0.0, 'Finance & Bills': 0.937, 'Job Application': 0.0, 'Newsletters': 0.0, 'Personal': 0.0, 'Promotions': 0.0, 'Reminders': 0.001, 'Travel & Bookings': 0.024}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #170 (ComplementNB)\n",
      "Raw text: Confirmation of Flight Booking Dear [Recipient], We are pleased to confirm your flight booking from New York to Los Angeles on November 15th, 2022. Your flight details are as follows: Flight Number: XY123 Departure: 8:00 AM Arrival: 10:30 AM Please ensure you arrive at the airport at least 2 hours prior to departure. If you have any questions or need assistance, feel free to contact us. We look fo ...\n",
      "Cleaned text: confirm flight book dear pleas confirm flight book new york lo angel novemb 15th 2022 flight detail follow flight number xy123 departur 00 arriv 10 30 pleas ensur arriv airport least hour prior departur question need assist feel free contact us look forward welcom board safe travel ...\n",
      "True labels: ['Travel & Bookings']\n",
      "Predicted labels: ['Travel & Bookings']\n",
      "Probabilities: {'Business': 0.0, 'Customer Support': 0.0, 'Events & Invitations': 0.0, 'Finance & Bills': 0.0, 'Job Application': 0.0, 'Newsletters': 0.0, 'Personal': 0.0, 'Promotions': 0.0, 'Reminders': 0.0, 'Travel & Bookings': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Select specific test examples to analyze\n",
    "example_indices = [15, 72, 170]\n",
    "\n",
    "# Loop through each example\n",
    "for idx in example_indices:\n",
    "    # Preprocess the email text\n",
    "    email_text_processed = preprocess_email(X_test_raw[idx])\n",
    "    \n",
    "    # Transform to TF-IDF vector\n",
    "    vec = vectorizer.transform([email_text_processed])\n",
    "    \n",
    "    # Get prediction probabilities for all labels\n",
    "    proba = clf_cnb.predict_proba(vec)[0]\n",
    "    \n",
    "    # Convert probabilities to binary predictions (threshold = 0.5)\n",
    "    pred_bin = (proba >= 0.5).astype(int)\n",
    "    \n",
    "    # Extract predicted label names\n",
    "    pred_labels = [mlb.classes_[i] for i, val in enumerate(pred_bin) if val == 1]\n",
    "\n",
    "    # Display results\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Example #{idx} (ComplementNB)\")\n",
    "    print(\"Raw text:\", X_test_raw[idx][:400], \"...\")\n",
    "    print(\"Cleaned text:\", email_text_processed[:400], \"...\")\n",
    "    print(\"True labels:\", labels_test_raw[idx])\n",
    "    print(\"Predicted labels:\", pred_labels)\n",
    "    print(\"Probabilities:\", {k: round(v, 3) for k, v in zip(mlb.classes_, proba)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0f5823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Example #15 (MultinomialNB)\n",
      "Raw text: Important Update: Company Policy Changes Dear Team, I hope this email finds you well. I wanted to inform you about some recent updates to our company policies. These changes are aimed at improving efficiency and ensuring compliance with industry standards. Please review the attached document for detailed information. Should you have any questions or need further clarification, feel free to reach o ...\n",
      "Cleaned text: import updat compani polici chang dear team hope email find well want inform recent updat compani polici chang aim improv effici ensur complianc industri standard pleas review attach document detail inform question need clarif feel free reach thank attent matter best regard ...\n",
      "True labels: ['Business', 'Customer Support']\n",
      "Predicted labels: ['Business', 'Customer Support']\n",
      "Probabilities: {'Business': 0.979, 'Customer Support': 0.539, 'Events & Invitations': 0.002, 'Finance & Bills': 0.006, 'Job Application': 0.0, 'Newsletters': 0.0, 'Personal': 0.0, 'Promotions': 0.0, 'Reminders': 0.001, 'Travel & Bookings': 0.001}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #72 (MultinomialNB)\n",
      "Raw text: Important Updates Regarding Your Account Dear Customer, We are writing to inform you about some important updates related to your account. Please log in to your account to review the changes and ensure that your information is up to date. If you have any questions or need assistance, feel free to contact our customer support team. Thank you for your attention to this matter. Sincerely, [Company Na ...\n",
      "Cleaned text: import updat regard account dear custom write inform import updat relat account pleas log account review chang ensur inform date question need assist feel free contact custom support team thank attent matter sincer ...\n",
      "True labels: ['Customer Support', 'Finance & Bills']\n",
      "Predicted labels: ['Finance & Bills']\n",
      "Probabilities: {'Business': 0.035, 'Customer Support': 0.187, 'Events & Invitations': 0.0, 'Finance & Bills': 0.742, 'Job Application': 0.0, 'Newsletters': 0.0, 'Personal': 0.0, 'Promotions': 0.0, 'Reminders': 0.0, 'Travel & Bookings': 0.004}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #170 (MultinomialNB)\n",
      "Raw text: Confirmation of Flight Booking Dear [Recipient], We are pleased to confirm your flight booking from New York to Los Angeles on November 15th, 2022. Your flight details are as follows: Flight Number: XY123 Departure: 8:00 AM Arrival: 10:30 AM Please ensure you arrive at the airport at least 2 hours prior to departure. If you have any questions or need assistance, feel free to contact us. We look fo ...\n",
      "Cleaned text: confirm flight book dear pleas confirm flight book new york lo angel novemb 15th 2022 flight detail follow flight number xy123 departur 00 arriv 10 30 pleas ensur arriv airport least hour prior departur question need assist feel free contact us look forward welcom board safe travel ...\n",
      "True labels: ['Travel & Bookings']\n",
      "Predicted labels: ['Travel & Bookings']\n",
      "Probabilities: {'Business': 0.0, 'Customer Support': 0.0, 'Events & Invitations': 0.0, 'Finance & Bills': 0.0, 'Job Application': 0.0, 'Newsletters': 0.0, 'Personal': 0.0, 'Promotions': 0.0, 'Reminders': 0.0, 'Travel & Bookings': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the same examples using MultinomialNB\n",
    "for idx in example_indices:\n",
    "    # Preprocess and vectorize\n",
    "    email_text_processed = preprocess_email(X_test_raw[idx])\n",
    "    vec = vectorizer.transform([email_text_processed])\n",
    "    \n",
    "    # Get predictions from MultinomialNB model\n",
    "    proba = clf_mnb.predict_proba(vec)[0]\n",
    "    pred_bin = (proba >= 0.5).astype(int)\n",
    "    pred_labels = [mlb.classes_[i] for i, val in enumerate(pred_bin) if val == 1]\n",
    "\n",
    "    # Display results\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Example #{idx} (MultinomialNB)\")\n",
    "    print(\"Raw text:\", X_test_raw[idx][:400], \"...\")\n",
    "    print(\"Cleaned text:\", email_text_processed[:400], \"...\")\n",
    "    print(\"True labels:\", labels_test_raw[idx])\n",
    "    print(\"Predicted labels:\", pred_labels)\n",
    "    print(\"Probabilities:\", {k: round(v, 3) for k, v in zip(mlb.classes_, proba)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15fb9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Example #15 (LogisticRegression)\n",
      "Raw text: Important Update: Company Policy Changes Dear Team, I hope this email finds you well. I wanted to inform you about some recent updates to our company policies. These changes are aimed at improving efficiency and ensuring compliance with industry standards. Please review the attached document for detailed information. Should you have any questions or need further clarification, feel free to reach o ...\n",
      "Cleaned text: import updat compani polici chang dear team hope email find well want inform recent updat compani polici chang aim improv effici ensur complianc industri standard pleas review attach document detail inform question need clarif feel free reach thank attent matter best regard ...\n",
      "True labels: ['Business', 'Customer Support']\n",
      "Predicted labels: ['Business', 'Customer Support']\n",
      "Probabilities: {'Business': 0.83, 'Customer Support': 0.675, 'Events & Invitations': 0.101, 'Finance & Bills': 0.093, 'Job Application': 0.025, 'Newsletters': 0.033, 'Personal': 0.056, 'Promotions': 0.012, 'Reminders': 0.044, 'Travel & Bookings': 0.056}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #72 (LogisticRegression)\n",
      "Raw text: Important Updates Regarding Your Account Dear Customer, We are writing to inform you about some important updates related to your account. Please log in to your account to review the changes and ensure that your information is up to date. If you have any questions or need assistance, feel free to contact our customer support team. Thank you for your attention to this matter. Sincerely, [Company Na ...\n",
      "Cleaned text: import updat regard account dear custom write inform import updat relat account pleas log account review chang ensur inform date question need assist feel free contact custom support team thank attent matter sincer ...\n",
      "True labels: ['Customer Support', 'Finance & Bills']\n",
      "Predicted labels: ['Customer Support', 'Finance & Bills']\n",
      "Probabilities: {'Business': 0.359, 'Customer Support': 0.678, 'Events & Invitations': 0.03, 'Finance & Bills': 0.581, 'Job Application': 0.017, 'Newsletters': 0.026, 'Personal': 0.028, 'Promotions': 0.013, 'Reminders': 0.048, 'Travel & Bookings': 0.094}\n",
      "--------------------------------------------------------------------------------\n",
      "Example #170 (LogisticRegression)\n",
      "Raw text: Confirmation of Flight Booking Dear [Recipient], We are pleased to confirm your flight booking from New York to Los Angeles on November 15th, 2022. Your flight details are as follows: Flight Number: XY123 Departure: 8:00 AM Arrival: 10:30 AM Please ensure you arrive at the airport at least 2 hours prior to departure. If you have any questions or need assistance, feel free to contact us. We look fo ...\n",
      "Cleaned text: confirm flight book dear pleas confirm flight book new york lo angel novemb 15th 2022 flight detail follow flight number xy123 departur 00 arriv 10 30 pleas ensur arriv airport least hour prior departur question need assist feel free contact us look forward welcom board safe travel ...\n",
      "True labels: ['Travel & Bookings']\n",
      "Predicted labels: ['Travel & Bookings']\n",
      "Probabilities: {'Business': 0.026, 'Customer Support': 0.036, 'Events & Invitations': 0.024, 'Finance & Bills': 0.021, 'Job Application': 0.013, 'Newsletters': 0.018, 'Personal': 0.021, 'Promotions': 0.011, 'Reminders': 0.018, 'Travel & Bookings': 0.962}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the same examples using Logistic Regression\n",
    "for idx in example_indices:\n",
    "    # Preprocess and vectorize\n",
    "    email_text_processed = preprocess_email(X_test_raw[idx])\n",
    "    vec = vectorizer.transform([email_text_processed])\n",
    "    \n",
    "    # Get predictions from Logistic Regression model\n",
    "    proba = clf_lr.predict_proba(vec)[0]\n",
    "    pred_bin = (proba >= 0.5).astype(int)\n",
    "    pred_labels = [mlb.classes_[i] for i, val in enumerate(pred_bin) if val == 1]\n",
    "\n",
    "    # Display results\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Example #{idx} (LogisticRegression)\")\n",
    "    print(\"Raw text:\", X_test_raw[idx][:400], \"...\")\n",
    "    print(\"Cleaned text:\", email_text_processed[:400], \"...\")\n",
    "    print(\"True labels:\", labels_test_raw[idx])\n",
    "    print(\"Predicted labels:\", pred_labels)\n",
    "    print(\"Probabilities:\", {k: round(v, 3) for k, v in zip(mlb.classes_, proba)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa15510",
   "metadata": {},
   "source": [
    "## Example Analysis – Multilabel Classification\n",
    "\n",
    "**ComplementNB:** Consistently predicted all true labels correctly, even for multi-label emails. Probabilities show strong confidence for correct classes. Handles imbalanced and multi-label cases well.\n",
    "\n",
    "**MultinomialNB:** Correct on simpler examples, but missed one label in a multi-label case (Example #72), showing lower recall for certain classes.\n",
    "\n",
    "**Logistic Regression:** Predicted all labels correctly in most cases, with slightly lower probability scores compared to ComplementNB, but more balanced across classes.\n",
    "\n",
    "Takeaway:\n",
    "ComplementNB is strong on multi-label prediction with high confidence, MultinomialNB is faster but can miss labels, and Logistic Regression is stable and balanced across diverse examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
